version: "3.9"

services:
  db:
    image: postgres:13
    container_name: pmbot-db
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: mydatabase
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d mydatabase"]
      interval: 5s
      timeout: 5s
      retries: 10
    networks:
      - pmbot-net

  pmbot-backend:
    build:
      context: ./backend
    container_name: pmbot-backend
    # --- CHANGE 1: 'command' line removed ---
    # The 'docker-entrypoint.sh' file already handles starting uvicorn.
    # This line was bypassing the database setup in that script.
    env_file:
      - ./backend/.env
    environment:
      # --- CHANGE 2: Paths updated from /app to /backend ---
      # This matches the WORKDIR set in your backend/Dockerfile.
      PYTHONPATH: /backend
      PM_QUESTIONS_CSV: /backend/PM_Questions_FINAL_12x2000_Formatted_Final_HUMANIZED.csv
      CORS_ORIGINS: http://localhost:3000,http://localhost:5173
      DATABASE_URL: postgresql://user:password@db:5432/mydatabase
      # Point the backend at the LLM wrapper service (Flask on port 5000)
      LLM_API_URL: http://pmbot-llm-stub:5000
      # Preferred model to use with Ollama
      LLM_MODEL: "qwen2:7b-instruct"
      # Enforce using the LLM
      LLM_FORCE: "1"
    volumes:
      # --- CHANGE 3: Volume mount updated from /app to /backend ---
      - ./backend:/backend
    # Ensure the mounted script has Unix line endings and is executable at container start.
    # On Windows hosts a bind mount can overwrite image permissions and leave CRLF endings.
    entrypoint: ["sh","-c","dos2unix /backend/docker-entrypoint.sh 2>/dev/null || true; chmod +x /backend/docker-entrypoint.sh 2>/dev/null || true; /backend/docker-entrypoint.sh"]
    ports:
      - "8000:8000"
    depends_on:
      db:
        condition: service_healthy
      pmbot-llm-stub:
        condition: service_started
    networks:
      - pmbot-net

  pmbot-frontend:
    build:
      context: ./Frontend
    container_name: pmbot-frontend
    environment:
      # Frontend is served to the host browser; API base should be host-reachable
      VITE_API_BASE: http://localhost:8000
      REACT_APP_API_BASE: http://localhost:8000
      NEXT_PUBLIC_API_BASE: http://localhost:8000
    # The Frontend Dockerfile starts Vite on port 3000, so map host:container 3000:3000.
    # If you'd rather use 5173 update the Frontend Dockerfile CMD to use --port 5173 instead.
    ports:
      - "3000:3000"
    depends_on:
      - pmbot-backend
    networks:
      - pmbot-net

  pmbot-llm-stub:
    build:
      context: ./backend/llm_stub
    container_name: pmbot-llm-stub
    ports:
      - "5000:5000"    # Flask wrapper only (Ollama runs on host)
    environment:
      # On Windows Docker Desktop, host.docker.internal resolves to the host machine
      OLLAMA_URL: http://host.docker.internal:11434
      # Fallback models (not used if OLLAMA_URL is reachable)
      LLM_MODEL: qwen2:7b-instruct
    networks:
      - pmbot-net

volumes:
  postgres_data:

networks:
  pmbot-net:
    driver: bridge