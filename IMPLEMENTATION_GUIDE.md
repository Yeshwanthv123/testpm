# ðŸ”§ Port & Configuration Fixes - Complete Guide

## What Was Fixed

### 1. **Path Mismatch Issue** âœ…
**Problem:** Config.py was looking for `/app/.env` but docker-compose mounts to `/backend`
- **File Changed:** `backend/app/config.py` 
- **Fix:** Updated env_file path from `/app/.env` to `/backend/.env`
- **Impact:** Backend can now properly read environment variables in Docker

### 2. **Port Conflict Prevention** âœ…
**Problem:** No mechanism to detect or handle port conflicts on different machines
- **Files Created:**
  - `scripts/diagnose_ports.py` - Python script to check port availability
  - `scripts/smart_start.ps1` - PowerShell script with port conflict detection
  - `scripts/smart_start.py` - Python universal startup script
- **Impact:** Automatic detection of port conflicts before starting Docker

### 3. **Documentation & Guides** âœ…
**Problem:** No clear guidance on how to handle port changes
- **Files Created:**
  - `PORT_MANAGEMENT_GUIDE.md` - Complete port management strategy
  - `AI_MODEL_ZERO_SCORE_FIX.md` - Troubleshooting guide for zero scores
  - This file - Implementation and next steps
- **Impact:** Step-by-step instructions for every scenario

### 4. **Integration Testing** âœ…
**Problem:** No way to verify all services are connected properly
- **File Created:** `scripts/integration_test.py` - Comprehensive service verification
- **Impact:** Can verify the entire service chain works before testing

---

## How to Use These Fixes

### Step 1: Check Port Availability (BEFORE starting Docker)

**On Windows:**
```powershell
python scripts/diagnose_ports.py
```

**On Mac/Linux:**
```bash
python3 scripts/diagnose_ports.py
```

This will show:
```
ðŸ” PMBOT Port & Service Diagnostic
============================================================

ðŸ“¦ Docker Status:
âœ… Docker is running

ðŸ”— Port Status:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   8000 - Backend API                      âœ… FREE
   3000 - Frontend (Vite)                  âœ… FREE
   5432 - PostgreSQL                       âœ… FREE
   5000 - LLM Wrapper                      âœ… FREE
  11434 - Ollama (host)                    âœ… FREE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âœ… All ports are available! Safe to start Docker.
```

### Step 2: Start Docker with Smart Port Detection

**Option A: Using PowerShell (Windows)**
```powershell
./scripts/smart_start.ps1
```

**Option B: Using Python (All platforms)**
```bash
python3 scripts/smart_start.py
```

**Option C: Manual Docker (if you know ports are free)**
```bash
docker-compose up --build
```

### Step 3: Verify All Services Are Connected

**After Docker successfully starts:**
```bash
python3 scripts/integration_test.py
```

Expected output:
```
ðŸ” PMBOT Integration Test
============================================================

âœ… PASS - Backend Health
âœ… PASS - Frontend Accessibility
âœ… PASS - Environment Variables
âœ… PASS - Backend â†’ LLM Connection
âœ… PASS - LLM â†’ Ollama Connection
âœ… PASS - Database Connection
âœ… PASS - API Endpoint

ðŸŽ‰ All tests passed! System is ready.
```

---

## If Ports Are In Use (What to Do)

### Scenario 1: Port 8000 is Already in Use

The diagnostic script will show:
```
âŒ Port 8000 (Backend) is IN USE
   Process: chrome.exe (PID: 12345)
   Suggestion: Use port 8001
```

**Fix:**

1. **Edit `docker-compose.yml`:**
   ```yaml
   pmbot-backend:
     ports:
       - "8001:8000"  # Changed from 8000:8000
   ```

2. **Edit `docker-compose.yml` frontend section:**
   ```yaml
   pmbot-frontend:
     environment:
       VITE_API_BASE: http://localhost:8001  # Must match host port
   ```

3. **Restart:**
   ```bash
   docker-compose down
   docker-compose up --build
   ```

### Scenario 2: Multiple Ports Are In Use

The diagnostic will suggest free ports. Use the same process for each:
- Change port in docker-compose.yml
- Update corresponding environment variable
- Restart Docker

---

## Understanding the Service Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (Vite)                       â”‚
â”‚               http://localhost:3000                      â”‚
â”‚              Container Port: 3000                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    API Request (HTTP)
                    /api/interview/*
                             â”‚
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BACKEND (FastAPI)                      â”‚
â”‚               http://localhost:8000                      â”‚
â”‚              Container Port: 8000                        â”‚
â”‚                                                          â”‚
â”‚  Environment Variables (from docker-compose):           â”‚
â”‚  - LLM_API_URL=http://pmbot-llm-stub:5000  âœ… Service name â”‚
â”‚  - LLM_MODEL=qwen2:7b-instruct                          â”‚
â”‚  - LLM_FORCE=1                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    Internal Docker Network
                  (uses service names, not localhost)
                             â”‚
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LLM WRAPPER (Flask)                         â”‚
â”‚          http://pmbot-llm-stub:5000                     â”‚
â”‚          Container Port: 5000                           â”‚
â”‚                                                          â”‚
â”‚  Environment Variables:                                 â”‚
â”‚  - OLLAMA_URL=http://host.docker.internal:11434  âœ… Hostâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    Escape Docker to Host
                 (host.docker.internal)
                             â”‚
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 OLLAMA (Host Machine)                    â”‚
â”‚               http://localhost:11434                    â”‚
â”‚  Must be running on host before Docker starts           â”‚
â”‚                    (NOT in Docker)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Critical Points:**
- âœ… Within Docker: Use service names (pmbot-llm-stub)
- âœ… From Host: Use localhost (http://localhost:8000)
- âœ… Escaping Docker: Use host.docker.internal

---

## Troubleshooting Checklist

Before assuming something is broken, verify:

### Before Starting Docker
- [ ] Run `python3 scripts/diagnose_ports.py`
- [ ] All 4 ports are FREE (8000, 3000, 5000, 5432)
- [ ] Ollama is running: `ollama serve`
- [ ] Qwen2 model is pulled: `ollama pull qwen2:7b-instruct`

### After Docker Starts
- [ ] Run `python3 scripts/integration_test.py`
- [ ] All tests should pass (green âœ…)
- [ ] Check backend logs: `docker logs pmbot-backend`
- [ ] Check LLM logs: `docker logs pmbot-llm-stub`

### If Tests Fail
1. Check which test failed
2. Read the error message carefully
3. Follow the suggested fix
4. Consult `AI_MODEL_ZERO_SCORE_FIX.md` for detailed troubleshooting

---

## Common Issues & Quick Fixes

| Issue | Quick Fix |
|-------|-----------|
| "Address already in use" | Run diagnose_ports.py, change port in docker-compose.yml |
| "Connection refused" | Make sure Docker container is running: `docker ps` |
| "AI model score is 0" | Run integration_test.py to find which connection failed |
| "Frontend blank page" | Check browser console errors, verify VITE_API_BASE |
| "CORS error" | Verify CORS_ORIGINS in docker-compose.yml includes frontend URL |
| "Cannot connect to Ollama" | Ensure Ollama is running on host: `ollama serve` |

---

## Files Changed/Created

### Modified Files
1. **`backend/app/config.py`**
   - Changed: `/app/.env` â†’ `/backend/.env`
   - Reason: Match docker-compose mount point

### New Files Created
1. **`PORT_MANAGEMENT_GUIDE.md`** - Strategic guide for port management
2. **`AI_MODEL_ZERO_SCORE_FIX.md`** - Comprehensive troubleshooting guide
3. **`IMPLEMENTATION_GUIDE.md`** - This file
4. **`scripts/diagnose_ports.py`** - Port availability checker
5. **`scripts/smart_start.ps1`** - Windows PowerShell startup script
6. **`scripts/smart_start.py`** - Python startup script (all platforms)
7. **`scripts/integration_test.py`** - Service connectivity verifier

---

## Next Steps

### For Your Next Test Session

1. **Before starting:**
   ```bash
   python3 scripts/diagnose_ports.py
   ```

2. **Start Docker:**
   ```bash
   ./scripts/smart_start.ps1  # Windows
   # OR
   python3 scripts/smart_start.py  # All platforms
   ```

3. **Verify all services:**
   ```bash
   python3 scripts/integration_test.py
   ```

4. **Run interview test:**
   - Open http://localhost:3000
   - Go through interview flow
   - Verify scores are NOT zero

### If Something Goes Wrong

1. **Stop everything:**
   ```bash
   docker-compose down
   ```

2. **Diagnose:**
   ```bash
   python3 scripts/integration_test.py
   ```

3. **Check logs:**
   ```bash
   docker logs pmbot-backend 2>&1 | tail -50
   docker logs pmbot-llm-stub 2>&1 | tail -50
   ```

4. **Refer to troubleshooting guides:**
   - `AI_MODEL_ZERO_SCORE_FIX.md` for connection issues
   - `PORT_MANAGEMENT_GUIDE.md` for port-related issues

---

## Key Takeaways

### Root Causes of Your Previous Issues
1. **Port conflicts not detected** â†’ Fixed with diagnose_ports.py
2. **Path mismatches** â†’ Fixed in config.py
3. **No verification of service connectivity** â†’ Fixed with integration_test.py
4. **Manual port changes broke everything** â†’ Fixed with proper docs and scripts

### How These Fixes Prevent Future Issues
- âœ… Automatic port conflict detection
- âœ… Clear instructions for port changes
- âœ… Automated verification that everything works
- âœ… Comprehensive troubleshooting guides
- âœ… Environment variables properly configured

### Remember
- **Change ONE port** â†’ Update BOTH docker-compose AND frontend env
- **Test BEFORE debugging** â†’ Run integration_test.py first
- **Check logs FIRST** â†’ Errors in logs explain 90% of problems
- **Use service names in Docker** â†’ pmbot-llm-stub, not localhost

---

## Questions?

1. Check `PORT_MANAGEMENT_GUIDE.md` for port strategy
2. Check `AI_MODEL_ZERO_SCORE_FIX.md` for connection issues
3. Run `scripts/integration_test.py` to identify problems
4. Check docker logs: `docker logs pmbot-backend`

Good luck with your next test! ðŸš€
